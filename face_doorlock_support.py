#! /usr/bin/env python3
#  -*- coding: utf-8 -*-
#
# Support module generated by PAGE version 8.0
#  in conjunction with Tcl version 8.6
#    Apr 05, 2025 10:07:29 AM JST  platform: Windows NT
from tensorflow.python.ops.gen_nn_ops import fractional_max_pool
from tensorflow.python.ops.metrics_impl import false_negatives

import face_doorlock
import sys
import tkinter as tk
import tkinter.ttk as ttk
from tkinter.constants import *
import time

import cv2
from tkinter import *
from PIL import Image, ImageTk

import tensorflow
from tensorflow.keras.models import load_model

import numpy as np
from numpy import argmax

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # INFO 로그 표시하지 않기

# mapping = {0:"김병만", 1:"구도윤", 2:"안제욱", 3:"강서현", 4:"김민준"}
mapping = {0:"김병만", 1:"구도윤", 2:"안제욱", 3:"김민준", 4:"강서현"} # 원래 mapping

_debug = True # False to eliminate debug printing from callback functions.

input_var = ""
pass_state = ""
pwfile = open("password_file.txt", "r")
password = pwfile.readline()
cur_state = "input"
cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # cap = cv2.VideoCapture("test.mp4")

# load the model from file
model = load_model('model.keras')

def main():
    '''Main entry point for the application.'''
    global root
    root = tk.Tk()
    root.protocol( 'WM_DELETE_WINDOW' , root.destroy)
    # Creates a toplevel widget.
    global _top1, _w1
    _top1 = root
    _w1 = face_doorlock.Toplevel1(_top1)

    global detector
    detector = init_detect()

    if not cap.isOpened():
        raise ValueError("Unable to open video source", 0)

    # video_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    # video_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
    # canvas = Canvas(root, width=video_width, height=video_height)
    display_video()

    root.mainloop()

def btn_0_clk():
    global input_var
    input_var += "0"
    print(input_var)
    pwcheck()

def btn_1_clk():
    global input_var
    input_var += "1"
    print(input_var)
    pwcheck()

def btn_2_clk():
    global input_var
    input_var += "2"
    print(input_var)
    pwcheck()

def btn_3_clk():
    global input_var
    input_var += "3"
    print(input_var)
    pwcheck()

def btn_4_clk():
    global input_var
    input_var += "4"
    print(input_var)
    pwcheck()

def btn_5_clk():
    global input_var
    input_var += "5"
    print(input_var)
    pwcheck()

def btn_6_clk():
    global input_var
    input_var += "6"
    print(input_var)
    pwcheck()

def btn_7_clk():
    global input_var
    input_var += "7"
    print(input_var)
    pwcheck()

def btn_8_clk():
    global input_var
    input_var += "8"
    print(input_var)
    pwcheck()

def btn_9_clk():
    global input_var
    input_var += "9"
    print(input_var)
    pwcheck()

def btn_sharp_clk():
    global input_var, cur_state, pass_state

    if cur_state == "input":
        if pass_state == "passive":
            print("xxxx")
            _w1.msg_var.set("비밀번호를 입력해주세요.")
            root.after_cancel(rttimer)
            pass_state = "auto"
        else:
            cur_state = "change_check"
            input_reset()
        return

    if cur_state == "change_check":
        if input_var != password:
            _w1.msg_var.set("비밀번호가 일치하지 않습니다.")
            input_reset()
            cur_state = "input"

        if input_var == password:
            _w1.msg_var.set("변경하실 비밀번호를 입력해주세요.")
            cur_state = "reset"
            input_reset()

        return

    if cur_state == "reset":
        pw_change()
        return

def btn_star_clk():
    global input_var, pass_state

    pass_state = "passive"

    if pass_state == "auto":
        input_var += "*"

    print(input_var)
    pwcheck()

def btn_reset():
    global input_var
    input_reset()
    _w1.msg_var.set("입력이 초기화되었습니다.")

if __name__ == '__main__':
    face_doorlock.start_up()

def pwcheck():
    global input_var, rttimer

    if (password == input_var) and (cur_state=="input"):
        _w1.msg_var.set("잠금이 해제되었습니다.")
        input_reset()
        rttimer = root.after(150, display_video)

def pw_change():
    global input_var, password, cur_state
    password = input_var
    _w1.msg_var.set("정상적으로 변경되었습니다.")
    cur_state = "input"
    input_reset()

def input_reset():
    global input_var
    input_var = ""


def resizeCover(src_w, src_h, dst_w, dst_h):
    src_ratio = src_w / src_h
    dst_ratio = dst_w / dst_h

    if src_ratio > dst_ratio:
        # Source is wider than destination: height is the constraint
        new_h = dst_h
        new_w = int(dst_h * src_ratio)
    else:
        # Source is taller than destination: width is the constraint
        new_w = dst_w
        new_h = int(dst_w / src_ratio)

    return new_w, new_h


# def cap_frame(cap: cv2.VideoCapture):
#     ret, frame = cap.read()
#     if not ret:
#         return False
#
#     canvasW, canvasH = _w1.Canvas1.winfo_width(), _w1.Canvas1.winfo_height()
#     w, h = cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
#     w, h = resizeCover(w, h, canvasW, canvasH)
#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
#     resized_frame = cv2.resize(frame, (160, 160))
#     frame = cv2.resize(frame, (w, h))
#     global model
#
#     resized_frame_np = np.array(resized_frame, dtype=np.float32)
#
#     input_batch = np.expand_dims(resized_frame_np, axis=0)
#     print(f"Shape of input_batch for predict: {input_batch.shape}")
#
#     yhat = model.predict(input_batch)
#     global mapping
#     print(mapping[argmax(yhat)])
#     img = Image.fromarray(frame)
#     imgtk = ImageTk.PhotoImage(image=img)
#     _w1.camCache = imgtk
#
#     _w1.Canvas1.create_image(canvasW//2, canvasH//2, anchor=tk.CENTER, image=imgtk)
#     return True



def get_frame():
    success = True
    global cap
    if cap.isOpened():
        success, frame = cap.read()
        if success:
            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (331, 190))
            return (success, img)
        else: return (success, None)
    else: return (success, None)

def init_detect():
	cv2_base_dir = os.path.dirname(os.path.abspath(cv2.__file__))
	haar_model =  os.path.join(cv2_base_dir, 'data/haarcascade_frontalface_default.xml')
	face_detector = cv2.CascadeClassifier(haar_model)
	return face_detector

def display_video():
    ret, frame = get_frame()
    if ret:
        global photo # 반드시. 이부분놓지면영상출력되지않음

        img = Image.fromarray(frame)
        photo = ImageTk.PhotoImage(image=img)
        _w1.Canvas1.create_image(0, 0, image=photo, anchor=NW)

        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        clippedImg = detect_face(detector, frame)
        if clippedImg is not None:
            resized_frame = cv2.resize(clippedImg, (200, 200))
            resized_frame_np = np.array(resized_frame, dtype=np.float32)
            input_batch = np.expand_dims(resized_frame_np, axis=0)
            print(f"Shape of input_batch for predict: {input_batch.shape}")
            yhat = model.predict(input_batch)
            global mapping
            # print(mapping[argmax(yhat)])
            clientname = mapping[argmax(yhat)]

            _w1.msg_var.set(clientname+str(np.max(yhat)))

            if float(np.max(yhat)) < 0.95:
                _w1.msg_var.set("등록되지 않았습니다."+str(np.max(yhat)))

        else:
            _w1.msg_var.set("Face Not Found!!!")

    global rttimer
    rttimer = root.after(150, display_video)

def detect_face(face_detector, img):
	grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
	detected = face_detector.detectMultiScale(grayimg)
	if len(detected) == 0:
		return None
	else:
		(x, y, w, h) = detected[0]
		clippedimg = img[y:y+h, x:x+w]
		return clippedimg